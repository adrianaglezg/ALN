{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer parcial - Algorítmica numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera pate: **Preguntas teórico-prácticas** - sin apuntes, 60min, total 5 puntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "**[1.6 puntos]** - Los siguientes bloques de código evalúan operaciones sencillas. Sin embargo, los resultados que se obtienen no son intuitivos. Explica por qué se obtienen dichos resultados (**una/dos frases por item son suficientes**):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(a) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(0.1 + 0.1 + 0.1 == 0.3)  # \"False\"\n",
    "print(1 + 1 + 1 == 3) # \"True\"\n",
    "print(0.125 + 0.125 + 0.125 == 0.375) # \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">el primero el false por la precisión con la que se puede representar 0.1 computacionalmente, al ser 0.1 no representable como potencia de 2 tiene un error de maquina que se acumula y por eso no es exactamente igual a 0.3</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.30000000000000004\n",
      "0.30000000000000004\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "a = 0.1\n",
    "b = 0.1 * 3\n",
    "print(a)\n",
    "print(b)\n",
    "c = a + a + a\n",
    "print(c)\n",
    "\n",
    "print(0.125 + 0.125 + 0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "print(1.79e+308 / 0.1)  #inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">es infinito poruqe al dividir entre un número < 1 se hace más grande el numerador y por tanto no se podrá representar dando por supuesto qu ela solucion va a infinito</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = 6.9e-15\n",
    "print(100.0 + a == 100)  # True, pero\n",
    "print(1.0 + a == 1)  # False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">debido al error relativo. sumarle **a** a 100 tiene un error relativo del mucho menor orden que al sumarlo al 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(d)\n",
    "La función $f(x) = (1-\\cos(x)) / x^2$ se puede representar computacionalmente como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import cos\n",
    "def f(x: float) -> float:\n",
    "    return (1 - cos(x)) / x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matemáticamente, $f(0) = 0.5$. Sin embargo,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500000002820775\n",
      "0.7709882115452477\n"
     ]
    }
   ],
   "source": [
    "print(f(1.2e-4))  # 0.500, parece que es suficientemente preciso, pero acercando 'x' más a 0\n",
    "print(f(1.2e-8))  # 0.771, el valor se aleja del teórico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">por la cancelación catastrofica, al estar en el denominador y acercarse a valores muy proximos a 0 pues llega un punto en el que los errores se cuantifican</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "**[1 puntos] -** En aplicaciones que hacen un uso intensivo de la memoria, pero donde la exactitud no es demasiado importante (e.g. redes neuronales) en ocasiones se utiliza la precisión media (*half precision*). En esta representación de coma flotante, se reserva 1 bit para el signo $s$, 5 para el exponente $e$ y 10 para la parte fraccionaria de la mantisa $f$:\n",
    "$$x_F = \\left( -1 \\right)^{s} \\times 1.f \\times 2^{(e-15)}$$\n",
    "\n",
    "Calcula:\n",
    "   - El mayor y el menor número normal representable (positivo).\n",
    "   - Los valores de $(s, e, f)$ para el número $1$.\n",
    "   - El tamaño del *gap* por la derecha de $x=1$\n",
    "\n",
    "Basta con dejar los resultados indicados en base 10: por ejemplo, $2^{-3}$ ó $2^{7} \\times \\left( 1 + \\frac{2}{1024}\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">sin respuesta</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_precision(s: str, e: str, f: str):\n",
    "\n",
    "    sign = (-1)**int(s)\n",
    "    e = int(e, 2)\n",
    "    exponent_total = e - 15\n",
    "    mantissa = 1 + int(f, 2) * 2 ** (-len(f))\n",
    "    return sign * 2 ** exponent_total * mantissa\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.103515625e-05, 65504.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menor número normal representable (e = 00001, f = 0000000000)\n",
    "s_min = \"0\"\n",
    "e_min = \"00001\"\n",
    "f_min = \"0000000000\"\n",
    "min_value = half_precision(s_min, e_min, f_min)\n",
    "\n",
    "# Mayor número normal representable (e = 11110, f = 1111111111)\n",
    "s_max = \"0\"\n",
    "e_max = \"11110\"\n",
    "f_max = \"1111111111\"\n",
    "max_value = half_precision(s_max, e_max, f_max)\n",
    "\n",
    "(min_value, max_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "**[0.8 puntos] -** Las siguientes expresiones muestran los desarrollos de Taylor en $x=0$ de una función real de variable real $f(x)$, usando un paso $h$ que se supone pequeño:\n",
    "\n",
    "\n",
    "$$\n",
    "f(x-h)=f(x)-h f^{\\prime}(x)+\\frac{h^{2}}{2 !} f^{\\prime \\prime}(x)-\\frac{h^{3}}{3 !} f^{\\prime \\prime \\prime}(x)+\\frac{h^{4}}{4 !} f^{(4)}(x)-\\cdots \\qquad (a)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x-2 h)=f(x)-2 h f^{\\prime}(x)+\\frac{4h^{2}}{2 !} f^{\\prime \\prime}(x)-\\frac{8 h^{3}}{3 !} f^{\\prime \\prime \\prime}(x)+\\frac{16 h^{4}}{4!} f^{(4)}(x)-\\cdots  \\qquad (b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x-3 h)=f(x)-3 h f^{\\prime}(x) + \\frac{9 h^2}{2!} f^{\\prime \\prime}(x) - \\frac{27 h^3}{3!} f^{\\prime \\prime \\prime}(x) +\\frac{81h^{4}}{4!} f^{(4)}(x)- \\cdots (c)\n",
    "$$\n",
    "\n",
    "Deducir la fórmula de diferencias finitas atrasadas de orden 2 para la segunda derivada, $f''(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">respuesta correcra hecha a papel, no corregir</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "**[0.8 puntos]** Explica el concepto de condicionamiento aplicado a la resolución de sistemas lineales de la forma $Ax=b$. También, da respuesta a la siguiente cuestión: si un sistema lineal $Ax=b$ está mal condicionado, ¿pequeños errores en el vector de términos independientes $b$ podrían provocar un cambio significativo en la solución $x$? ¿O solo ocurre con las variaciones en $A$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">el condicionamiento aplicado a la resolución de sistemas lineales es el error que se produce al obtener una solución aproximada a un problema real que no tiene solución, ya sea por que las dimensiones no coinciden u otras condiciones. \n",
    "\n",
    "<span style=\"color: orange\">si el sistema está mal condicionado, un pequeño error en b supondría un gran error en la salida ya que en estos casos la matriz Ax es la salida del sistema y b la entrada.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "**[0.8 puntos] -** Explica el concepto de **abstracción** en OOP (programación orientada a objetos). Utiliza el siguiente código para ejemplificar las principales características que hayas resaltado. Puedes modificar el código como desees. En particular, instancia y/o haz llamadas a los distintos métodos para mostrar comportamientos destacados, explicándolos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miauu!\n",
      "guau!\n",
      "ñam, ñam!\n",
      "gr gr gr...\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Animal(ABC):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    @abstractmethod\n",
    "    def communicate(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def eat(self):\n",
    "        print(\"ñam, ñam!\")\n",
    "\n",
    "\n",
    "class Dog(Animal):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def communicate(self):\n",
    "        print(\"guau!\")\n",
    "    \n",
    "\n",
    "class Cat(Animal):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def communicate(self):\n",
    "        print(\"miauu!\")\n",
    "\n",
    "    def eat(self):\n",
    "        print(\"gr gr gr...\")\n",
    "\n",
    "\n",
    "class WeirdAnimal(Animal):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "\n",
    "\n",
    "gato = Cat('pocholo')\n",
    "perro = Dog('pepe')\n",
    "\n",
    "gato.communicate()\n",
    "perro.communicate()\n",
    "perro.eat()\n",
    "gato.eat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange\">la abstracción en python es un método que se le pasa a una clase padre de la cual luego heredarán otras clases. El qué heredan, pues aquellos métodos que hayamos definido dentro de la clase que tiene definido encima el abstracmethod de la Clase(ABC). sirve para que a la hora de definir las ClasesHijas(Clase) que heredan, estas no funcionen si no tienen los metodos abstractos implementados, ya que son oblia¡gatorios, pudiendo además tener métodos propios.\n",
    "Además si una clase no tiene definido un metodo no abstracto de la clase que herreda, heredará lo que la clase padre tenga en ese metodo por defecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
