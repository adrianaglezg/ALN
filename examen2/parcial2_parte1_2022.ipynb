{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segundo parcial - Algorítmica numérica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primera pate: **Preguntas teórico-prácticas** - sin apuntes, 60min, total 5 puntos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "**[1.2 puntos] -** Los siguientes bloques de código evalúan operaciones sencillas. Sin embargo, los resultados que se obtienen no son intuitivos. Explica por qué se obtienen dichos resultados (**una/dos frases por item son suficientes**):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.a)**\n",
    "\n",
    "Al evaluar la siguiente integral por el método de Simpson con 101 subintervalos, el resultado no tiene nada que ver con el valor real de la integral:\n",
    "$$\n",
    "\\int_{-5}^{5} \\left| \\frac{1}{x} \\right| \\, dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.77096667272374\n"
     ]
    }
   ],
   "source": [
    "from scipy import integrate\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-5, 5, 102)  # 102 nodos -> 101 subintervalos\n",
    "x = x[x != 0]  # Elimina el valor donde x = 0 para evitar división por cero\n",
    "y = np.abs(1 / x)  # Cálculo de y evitando la división por cero\n",
    "\n",
    "dx = x[1] - x[0]  # Tamaño de paso entre los valores de x\n",
    "I = integrate.simpson(y, dx=dx)\n",
    "\n",
    "print(I)  # Imprime el resultado aproximado de la integral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "\n",
    "import numpy as np\n",
    "x = np.linspace(-5, 5, 102)  # 102 nodos -> 101 subintervalos\n",
    "y = np.array([abs(1/x_val) for x_val in x])\n",
    "I = integrate.simpson(y, x)\n",
    "\n",
    "print(I)  # 11.77096, pero el resultado exacto de la integral es infinito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**respuesta :** estamos hablando de un numero impar de subintervalos, por lo que tenemos que aplicar la regla 3/8 de simpson. Probablemente lo que este pasando es que de error calculando la primera parte con la formula de h/3 ... pero que se quede solo con el área de los 3 últimos subintervalos con el 3h/8...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "**(1.b)**\n",
    "\n",
    "El siguiente código implementa un simple algoritmo iterativo que converge rápidamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 7 iterations\n"
     ]
    }
   ],
   "source": [
    "value = 1.0\n",
    "max_ite = 1000\n",
    "for i in range(max_ite):\n",
    "    value += 1.0\n",
    "\n",
    "    # Condición de parada\n",
    "    if value == 9.0:\n",
    "        print(f\"Converged in {i} iterations\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Failed to converge.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa ahora la siguiente modificación trivial del algoritmo anterior. Con esta modificación, el nuevo algoritmo no converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to converge.\n"
     ]
    }
   ],
   "source": [
    "value = 0.1  # CAMBIADO\n",
    "max_ite = 1000\n",
    "for i in range(max_ite):\n",
    "    value += 0.1  # CAMBIADO\n",
    "\n",
    "    # Condición de parada\n",
    "    if value == 0.9:  # CAMBIADO\n",
    "        print(f\"Converged in {i} iterations\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Failed to converge.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**respuesta:** lo que sucede aqui es que 1 es representable en binario y 0.1 no tiene una representación exacta. por lo que el error que va arrastrando 0.1 al ir sumandose hace que no sea igual a 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "**(1c)**\n",
    "\n",
    "Los mayores y menores números normales representables con precisión doble pueden obtenerse con el paquete ```sys``` usando ```sys.float_info.max``` y ```sys.float_info.min``` respectivamente. La multiplicación del número mayor por $100$ resulta en un desbordamiento (*overflow*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(100 * sys.float_info.max)  # overflow -> inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sin embargo, la división del número menor por $100$ no produce un *underflow* y la operación es calculada correctamente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2250738585072e-310\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.float_info.min / 100)  # 2.2250738585072e-310 -> resultado correcto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**respuesta :** lo que sucede es que el maximo numero normal representable, ya esta usando toda la capacidad de la mantisa, mientras que el minimo normal representable no. or o que al dividir entre 100 lo que estamos haciendo es reducir la precision de la mantisa para aumentar la reresentación del exponente. por tanto `sys.float_info.min` es el minimo numero normal representable pero hay numeros subnormales más pequeños."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "### Ejercicio 2\n",
    "\n",
    "**[1 punto]** - ¿Cómo se llama el método que permite adaptar el procedimiento de interpolación de Newton basado en la tabla de diferencias divididas para casos donde se disponga de información sobre la primera derivada de la función en los nodos? Describe detalladamente este método de **una** de las siguientes tres formas:\n",
    " - Escribe el pseudocódigo del algoritmo en cuestión.\n",
    " - Implementa en Python dicho algoritmo.\n",
    " - Describe *de palabra* el procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se llama interpolacion de hermite\n",
    "# voy a implementar un pseudo codigo: lo voy a dividir en 2 funciones, una que calcule lso coeficientes y otra que evalue el polinomio y uan auxiliar que no me defino que es el factorial\n",
    "\n",
    "def hermite_coefficients(x_data: list, y_data:list) -> list:\n",
    "    '''\n",
    "    aqui x_data contiene los datos de x\n",
    "    y_data es uan lista anidada donde e primero elemnto sera la derivada 0, es decir los valores de y\n",
    "    y el segundo elemento la primera derivada y asi sucesivamente\n",
    "    '''\n",
    "\n",
    "    feasible = len(todos los elemntos de y) = len(x)\n",
    "    #feasible es un booleano que indica si faltan datos en alguno de las derivadas\n",
    "    #si daltan datos se detiene la ejecucion con un valuerror\n",
    "    if not feasible:\n",
    "        raise ValueError(\" coudn't use this method due to missing data\")\n",
    "    \n",
    "    else:\n",
    "        x_values = [x por cada eleemento en x_data tantas veces como len(y_data)] # pq len(y_data) es el nuemro de datos que tenemso de x\n",
    "        y_values = [y por cada eleemento en y_data tantas veces como len(y_data)] \n",
    "        #almacenamos los coeficientes en uan lista vacia\n",
    "        coefficients = []\n",
    "        coefficients.append(y_values[0])\n",
    "        layer = 1 # es la capa de diferencia finita en al que estamso calculando\n",
    "        divided_diff = [] # para guardar los valores de las diferencias finitas y luego actualizar el y values\n",
    "\n",
    "        # tener en cuenta si el xi = xi+1 para dividir entre el factorial del orden de la derivada o hacer al dif finita nroaml\n",
    "\n",
    "        while len(y_values) > 1:\n",
    "            for i in range(len(y_values) - 1):\n",
    "\n",
    "                if x[i] == x[i + layer]:\n",
    "                    value = y_values[1 // len(x_data)] / factorial(layer)\n",
    "\n",
    "                else:\n",
    "                    value = (y_values[i + 1] - y_values[i]) / (x_values[i + layer] - x_values[i])\n",
    "\n",
    "                divided_diff.append(value)\n",
    "\n",
    "            coefficients.append(divided_diff[0])\n",
    "            y_values = divided_diff\n",
    "            layer += 1\n",
    "            divided_diff = [] #reseteamos la lista\n",
    "\n",
    "\n",
    "def evaluate_hermite(coefficients, x_data, y_data, x_eval) -> float:\n",
    "\n",
    "    herm_poly = coefficients[0] # el valor del polinomio\n",
    "    product = 1 #para ir acumulando el producto y no calcularlo para cada valro de la lista\n",
    "    x_values = [elemento for elemento in x_data for _ in range(len(y_data))] #repetios las x\n",
    "\n",
    "    for i in range(1, len(coefficients)):\n",
    "        product *= (x - x_values[i -1])\n",
    "\n",
    "        value = coefficients[i] * product\n",
    "        print('value = ', value, 'coef = ', coefficients[i], 'producto = ', product)\n",
    "        herm_poly += value\n",
    "\n",
    "        print(herm_poly)\n",
    "    \n",
    "    return herm_poly\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "### Ejercicio 3\n",
    "\n",
    "**[1 punto] -**  Deduce razonadamente el **número de ecuaciones de cierre** que será necesario imponer para cerrar el problema del cálculo de un **spline de orden 4** (es decir, cada tramo será ajustado por un polinomio de grado 4). Las condiciones generales a imponer son las mismas que las usadas para el cálculo de un spline cúbico + la condición de continuidad de la derivada 3ª en los nodos internos. Denota por $n+1$ el número de nodos disponibles ($x_0, x_1, \\dots , x_n$) y por $n$ el número de subintervalos, siendo $q_{i,i+1}(x)$ el polinomio que se extiende desde el nodo $i$ al $i+1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**respuesta:** partimos de que un splin de orden 4 tendra uan forma del tipo ax^4 + bx^3 + cx^2 + dx + e, por tanto tenemos 5 incognitas. como tenemos n+1 puntos tendremos n intervalos. por lo que tenemos 5n ecuaciones. \n",
    "\n",
    "ahora sabemos que por cada punto deben pasar dos ecuaciones, la de entrada y la de salida por asi decirlo. tambien que cada ecuacion pasa por dos puntos, el origen y el final del intervalo. eso nos deja 2n ecuaciones. \n",
    "\n",
    "\n",
    "imponemos ahora que q´i-1,i(x) = q´i,i+1(x) de donde salen n-1 ecuaciones, \n",
    "imponemos esto de igaul manera para q´´ y q´´´ de donde salen n-1 ecuaciones para cada uan\n",
    "\n",
    "\n",
    "esto nos queda 2n + (n-1) + (n-1) + (n-1) = 2n + 3(n-1) = 2n + 3n - 3 = 5n - 3\n",
    "\n",
    "se lo restamos a nuestro numero inicial de ecuaciones 5n - (5n - 3) = 3 ecuaciones de cierre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "### Ejercicio 4\n",
    "\n",
    "**[0.8 punto] -** La regresión multilineal sigue la misma idea que la regresión lineal univariante. Observa el siguiente caso: en un experimento se han obtenido los siguientes datos de una determinada función real $z(x,y)$:\n",
    "\n",
    " <center>\n",
    "\n",
    "|  x  |  y  |  z  |\n",
    "|-----|-----|-----|\n",
    "|  0  |  0  |  6  |\n",
    "|  0  |  0  | -2  |\n",
    "|  0  |  1  |  0  |\n",
    "| -1  |  0  |  0  |\n",
    "\n",
    " </center>\n",
    "\n",
    "Observa que ahora $x$ e $y$ son las variables independientes. Se desea obtener un modelo de la forma $\\hat{z} = a + bx + cy$ que ajuste dichos puntos. Minimiza el error cuadrático medio (igual que harías con una única variable independiente) para demostrar que los coeficientes del modelo deben ser $a=2$, $b=2$ y $c=-2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 2.0, b = 2.0000000000000004, c = -1.9999999999999993\n",
      "(array([ 2.,  2., -2.]), array([32.]), np.int32(3), array([2.13577921, 1.        , 0.66215345]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Matriz de variables independientes, incluyendo el término constante para 'a'\n",
    "X = np.array([\n",
    "    [1, 0, 0],  # 1 para 'a', 0 para 'x', 0 para 'y'\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 1],\n",
    "    [1, -1, 0]\n",
    "])\n",
    "\n",
    "# Vector de valores dependientes 'z'\n",
    "Z = np.array([6, -2, 0, 0])\n",
    "\n",
    "# Cálculo de los coeficientes mediante mínimos cuadrados\n",
    "coefficients = np.linalg.lstsq(X, Z)[0]\n",
    "nose = np.linalg.lstsq(X, Z)\n",
    "a, b, c = coefficients\n",
    "print(f\"a = {a}, b = {b}, c = {c}\")\n",
    "print(nose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "\n",
    "### Ejercicio 5\n",
    "\n",
    "**[1 punto] -** ¿Qué relación existe entre la regresión de Ridge y el fenómeno del *overfit* (sobre-ajuste)? ¿Qué magnitud se minimiza realmente en el cálculo de la regresión lineal de Ridge? Discute si es verdadera o falsa la siguiente afirmación: *\\\"Un modelo basado en la regresión de Ridge tendrá una mejor calidad de ajuste sobre el conjunto de datos de entrenamiento (es decir, un mayor coeficiente $R_{train}^2$) en comparación con el mismo modelo sin penalización de Ridge\\\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**respuesta :** la relacion que existe entre la regresion de ridge y el overfitting es que si tenemos un polinomio que interpola los datos o los ajusta mucho a los conocidos pero mal a los nuevos (overfit) la regresion de ridge lo que va a bsucar es aplanar ese polinomio de forma que sea mas general y prediga mejor datos nuevos. \n",
    "\n",
    "en la regrsion lineal de ridge la magnitud que se minimiza es el coeficiente de al x en uan recat de la forma r = a + bx, es decir que se minima b al multiplicarlo por un landa arbitrario. siempre que hagamos uan regresion linal, al aplicarle el coeficiente de ridge nos debe salir un valor de b menor a la recta que hemso predicho apra nuestro ajuste\n",
    "\n",
    "\n",
    "la frase no es necesariamente cierta. un modelo con regresion de ridge será menos oscilatorio y más plano pero eso no quiere decir que sea mejor. en una funcion socilatoria como puede ser el coseno, un polinomio de interpolacion probablemente sea mejor qe  un modelo con la penalizacion de ridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
