{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隆Entendido! Aqu铆 van **100 preguntas tipo verdadero/falso** organizadas por temas. **Primero te doy todas las preguntas** y despu茅s, en otra respuesta, te doy las soluciones con justificaciones.\n",
    "\n",
    "---\n",
    "\n",
    "### **Tema 2: Medida del error, representaci贸n num茅rica, errores y estabilidad**  \n",
    "1. El error absoluto mide la diferencia entre el valor aproximado y el valor exacto.  \n",
    "2. El error relativo se calcula como el cociente entre el error absoluto y el valor aproximado.  \n",
    "3. Los errores de redondeo son causados por el uso de operaciones infinitas en m茅todos num茅ricos.  \n",
    "4. El error de truncamiento proviene de aproximar procesos infinitos con m茅todos num茅ricos finitos.  \n",
    "5. La representaci贸n en coma flotante tiene una precisi贸n infinita.  \n",
    "6. La estabilidad num茅rica de un algoritmo depende del n煤mero de iteraciones realizadas.  \n",
    "7. El condicionamiento de un problema mide la sensibilidad de la soluci贸n respecto a peque帽as perturbaciones en los datos de entrada.  \n",
    "8. Un problema bien condicionado siempre produce soluciones precisas.  \n",
    "9. Los errores de cancelaci贸n catastr贸fica ocurren al restar n煤meros de magnitudes muy cercanas.  \n",
    "10. La precisi贸n de un m茅todo num茅rico puede mejorarse indefinidamente sin l铆mite.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Tema 3: Interpolaci贸n, ajuste e integraci贸n num茅rica**  \n",
    "**Interpolaci贸n y ajuste:**  \n",
    "11. El polinomio interpolante de Lagrange es 煤nico para un conjunto dado de puntos.  \n",
    "12. En interpolaci贸n, los polinomios de grado alto siempre ofrecen una mejor aproximaci贸n.  \n",
    "13. La interpolaci贸n de Hermite requiere la continuidad de la derivada en los puntos interpolados.  \n",
    "14. La interpolaci贸n lineal usa dos puntos para aproximar una funci贸n localmente.  \n",
    "15. En interpolaci贸n a trozos, se combinan polinomios de bajo grado.  \n",
    "16. El ajuste por m铆nimos cuadrados se utiliza cuando los datos contienen ruido.  \n",
    "17. El polinomio de Newton puede calcularse incrementalmente con diferencias divididas.  \n",
    "18. En interpolaci贸n c煤bica, el polinomio siempre tiene grado 4.  \n",
    "19. La interpolaci贸n spline c煤bica garantiza continuidad en la segunda derivada.  \n",
    "20. Los m茅todos de ajuste permiten encontrar funciones que se aproximan a un conjunto de datos.  \n",
    "\n",
    "**Integraci贸n num茅rica:**  \n",
    "21. La regla del trapecio es un m茅todo de integraci贸n num茅rica de segundo orden.  \n",
    "22. La regla de Simpson utiliza par谩bolas para aproximar el 谩rea bajo una curva.  \n",
    "23. La integraci贸n num茅rica siempre produce resultados exactos si la funci贸n es continua.  \n",
    "24. La precisi贸n de la regla de Simpson es mayor que la de la regla del trapecio.  \n",
    "25. El m茅todo de integraci贸n de Newton-Cotes se basa en la interpolaci贸n polin贸mica.  \n",
    "26. La cuadratura gaussiana permite obtener una alta precisi贸n con menos puntos.  \n",
    "27. La regla del punto medio tiene error de truncamiento de orden \\( h^2 \\).  \n",
    "28. La integraci贸n num茅rica puede ser inexacta si la funci贸n tiene oscilaciones pronunciadas.  \n",
    "29. En la cuadratura compuesta, el intervalo se divide en subintervalos m谩s peque帽os.  \n",
    "30. La cuadratura gaussiana requiere una funci贸n peso en la integraci贸n.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Tema 4: Resoluci贸n de sistemas lineales**  \n",
    "**M茅todos directos:**  \n",
    "31. La eliminaci贸n de Gauss es un m茅todo directo para resolver sistemas lineales.  \n",
    "32. El m茅todo de descomposici贸n LU descompone la matriz en una triangular inferior y superior.  \n",
    "33. El pivotamiento parcial evita problemas de estabilidad num茅rica.  \n",
    "34. El m茅todo LU funciona 煤nicamente para matrices cuadradas.  \n",
    "35. La descomposici贸n de Cholesky solo puede aplicarse a matrices sim茅tricas definidas positivas.  \n",
    "36. El m茅todo de Gauss-Jordan es una extensi贸n de la eliminaci贸n de Gauss.  \n",
    "37. El condicionamiento de una matriz afecta la precisi贸n en los m茅todos directos.  \n",
    "38. El pivotamiento completo intercambia filas y columnas para mejorar la estabilidad.  \n",
    "39. El m茅todo LU es m谩s eficiente que la eliminaci贸n de Gauss para resolver m煤ltiples sistemas con la misma matriz.  \n",
    "40. El tiempo computacional de la eliminaci贸n de Gauss es \\( O(n^3) \\) para una matriz \\( n \\times n \\).  \n",
    "\n",
    "**M茅todos iterativos:**  \n",
    "41. Los m茅todos iterativos se usan cuando las matrices son grandes y dispersas.  \n",
    "42. El m茅todo de Jacobi requiere que la matriz sea diagonalmente dominante.  \n",
    "43. El m茅todo de Gauss-Seidel converge m谩s r谩pido que el de Jacobi en la mayor铆a de los casos.  \n",
    "44. La convergencia en los m茅todos iterativos depende de la matriz del sistema.  \n",
    "45. Los m茅todos iterativos siempre producen soluciones exactas en un n煤mero finito de iteraciones.  \n",
    "46. La convergencia de un m茅todo iterativo puede acelerarse utilizando relajaci贸n.  \n",
    "47. El m茅todo de Sobrelajaci贸n Sucesiva (SOR) es una mejora del m茅todo de Gauss-Seidel.  \n",
    "48. La diagonal de la matriz influye directamente en la convergencia de los m茅todos iterativos.  \n",
    "49. Los m茅todos iterativos permiten resolver sistemas con menor costo computacional que los m茅todos directos.  \n",
    "50. La matriz identidad es diagonalmente dominante.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Tema 5: B煤squeda de ra铆ces**  \n",
    "51. El m茅todo de bisecci贸n siempre converge si \\( f(a)f(b) < 0 \\).  \n",
    "52. El m茅todo de Newton-Raphson tiene convergencia cuadr谩tica si la derivada no se anula.  \n",
    "53. El m茅todo de regula falsi utiliza una interpolaci贸n lineal entre dos puntos.  \n",
    "54. El m茅todo de bisecci贸n es m谩s r谩pido que Newton-Raphson.  \n",
    "55. En Newton-Raphson, si la derivada es cero, el m茅todo falla.  \n",
    "56. El m茅todo de la secante no requiere la derivada de la funci贸n.  \n",
    "57. La convergencia del m茅todo de la secante es superlineal.  \n",
    "58. El m茅todo de regula falsi garantiza convergencia incluso si la funci贸n es no lineal.  \n",
    "59. El m茅todo de bisecci贸n divide el intervalo en dos partes iguales en cada iteraci贸n.  \n",
    "60. Newton-Raphson puede no converger si el punto inicial est谩 lejos de la ra铆z.  \n",
    "61. El m茅todo de la secante necesita dos valores iniciales.  \n",
    "62. El m茅todo de Newton-Raphson requiere que la funci贸n sea diferenciable.  \n",
    "63. En el m茅todo de la falsa posici贸n, se actualiza siempre el extremo donde cambia el signo de la funci贸n.  \n",
    "64. El m茅todo de bisecci贸n converge de manera lineal.  \n",
    "65. La convergencia cuadr谩tica de Newton-Raphson lo hace m谩s eficiente que la bisecci贸n en general.  \n",
    "66. El m茅todo de la secante es una variante del m茅todo de Newton-Raphson.  \n",
    "67. La regla de Regula Falsi converge m谩s r谩pido que la bisecci贸n en funciones lineales.  \n",
    "68. Si la funci贸n tiene m煤ltiples ra铆ces, Newton-Raphson puede saltarse algunas.  \n",
    "69. El m茅todo de bisecci贸n requiere que la funci贸n sea continua en el intervalo dado.  \n",
    "70. El m茅todo de Newton-Raphson no necesita un intervalo inicial, solo un punto inicial.  \n",
    "\n",
    "---\n",
    "\n",
    "Estas son **70 preguntas** como adelanto. 驴Te parece bien o contin煤o hasta completar las **100**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隆Perfecto! Aqu铆 tienes las **70 preguntas** de los temas indicados (**verdadero/falso**) con **respuestas y justificaciones**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Respuestas Tema 2: Medida del error, representaci贸n num茅rica, errores y estabilidad**\n",
    "\n",
    "1. **Verdadero**. El error absoluto mide la diferencia entre el valor exacto y el aproximado.  \n",
    "2. **Falso**. El error relativo se calcula como el cociente entre el error absoluto y el **valor exacto** (no el aproximado).  \n",
    "3. **Falso**. Los errores de redondeo surgen al representar n煤meros con precisi贸n finita, no por operaciones infinitas.  \n",
    "4. **Verdadero**. El error de truncamiento surge al aproximar m茅todos num茅ricos.  \n",
    "5. **Falso**. La representaci贸n en coma flotante tiene precisi贸n **limitada**, no infinita.  \n",
    "6. **Falso**. La estabilidad no solo depende del n煤mero de iteraciones, sino de la propagaci贸n de errores.  \n",
    "7. **Verdadero**. El condicionamiento mide qu茅 tan sensible es la soluci贸n a peque帽os cambios en los datos.  \n",
    "8. **Falso**. Un problema bien condicionado no garantiza soluciones precisas si se usa un m茅todo inestable.  \n",
    "9. **Verdadero**. La cancelaci贸n catastr贸fica ocurre al restar n煤meros cercanos en magnitud.  \n",
    "10. **Falso**. Existe un l铆mite pr谩ctico para la precisi贸n debido a errores de m谩quina y truncamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## **Respuestas Tema 3: Interpolaci贸n, ajuste e integraci贸n num茅rica**\n",
    "\n",
    "11. **Verdadero**. El polinomio de Lagrange es 煤nico para un conjunto de puntos dados.  \n",
    "12. **Falso**. Los polinomios de grado alto pueden oscilar (efecto Runge) y ser menos precisos.  \n",
    "13. **Verdadero**. La interpolaci贸n de Hermite garantiza continuidad de la funci贸n y su derivada.  \n",
    "14. **Verdadero**. La interpolaci贸n lineal aproxima localmente con una recta entre dos puntos.  \n",
    "15. **Verdadero**. La interpolaci贸n a trozos usa polinomios de bajo grado en subintervalos.  \n",
    "16. **Verdadero**. El ajuste por m铆nimos cuadrados es 煤til cuando los datos tienen ruido.  \n",
    "17. **Verdadero**. El polinomio de Newton usa diferencias divididas de forma incremental.  \n",
    "18. **Falso**. En interpolaci贸n c煤bica, el polinomio es de **grado 3**, no 4.  \n",
    "19. **Verdadero**. Los splines c煤bicos garantizan continuidad hasta la segunda derivada.  \n",
    "20. **Verdadero**. Los m茅todos de ajuste encuentran funciones que aproximan datos reales.  \n",
    "\n",
    "**Integraci贸n num茅rica:**  \n",
    "21. **Verdadero**. La regla del trapecio tiene error de orden \\( h^2 \\).  \n",
    "22. **Verdadero**. Simpson aproxima con par谩bolas (grado 2) y es m谩s precisa.  \n",
    "23. **Falso**. La integraci贸n num茅rica no siempre es exacta, depende de la funci贸n y m茅todo.  \n",
    "24. **Verdadero**. Simpson es m谩s precisa porque tiene un error de orden \\( h^4 \\).  \n",
    "25. **Verdadero**. Newton-Cotes se basa en interpolaci贸n polin贸mica en subintervalos.  \n",
    "26. **Verdadero**. La cuadratura gaussiana logra mayor precisi贸n con menos puntos.  \n",
    "27. **Verdadero**. La regla del punto medio tiene error de orden \\( h^2 \\).  \n",
    "28. **Verdadero**. Las oscilaciones fuertes pueden reducir la precisi贸n de integraci贸n num茅rica.  \n",
    "29. **Verdadero**. La cuadratura compuesta divide el intervalo en subintervalos peque帽os.  \n",
    "30. **Verdadero**. La cuadratura gaussiana utiliza una funci贸n peso en la integraci贸n.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Respuestas Tema 4: Resoluci贸n de sistemas lineales**\n",
    "\n",
    "**M茅todos directos:**  \n",
    "31. **Verdadero**. La eliminaci贸n de Gauss es un m茅todo directo para resolver sistemas lineales.  \n",
    "32. **Verdadero**. La descomposici贸n LU descompone una matriz en \\( L \\) y \\( U \\) (inferior y superior).  \n",
    "33. **Verdadero**. El pivotamiento parcial mejora la estabilidad num茅rica.  \n",
    "34. **Verdadero**. LU solo funciona para matrices cuadradas.  \n",
    "35. **Verdadero**. La descomposici贸n de Cholesky aplica solo a matrices sim茅tricas definidas positivas.  \n",
    "36. **Verdadero**. Gauss-Jordan extiende Gauss para obtener la matriz inversa.  \n",
    "37. **Verdadero**. El condicionamiento afecta la precisi贸n al resolver un sistema.  \n",
    "38. **Verdadero**. El pivotamiento completo intercambia filas y columnas.  \n",
    "39. **Verdadero**. LU es eficiente si se resuelven m煤ltiples sistemas con la misma matriz.  \n",
    "40. **Verdadero**. La eliminaci贸n de Gauss tiene complejidad \\( O(n^3) \\).  \n",
    "\n",
    "**M茅todos iterativos:**  \n",
    "41. **Verdadero**. Los m茅todos iterativos son ideales para matrices grandes y dispersas.  \n",
    "42. **Verdadero**. El m茅todo de Jacobi requiere que la matriz sea diagonalmente dominante.  \n",
    "43. **Verdadero**. Gauss-Seidel converge m谩s r谩pido que Jacobi en la mayor铆a de casos.  \n",
    "44. **Verdadero**. La convergencia depende de las propiedades de la matriz.  \n",
    "45. **Falso**. Los m茅todos iterativos no siempre producen soluciones exactas.  \n",
    "46. **Verdadero**. La relajaci贸n acelera la convergencia en algunos m茅todos iterativos.  \n",
    "47. **Verdadero**. El m茅todo SOR es una versi贸n mejorada de Gauss-Seidel.  \n",
    "48. **Verdadero**. La diagonal influye directamente en la convergencia de iterativos.  \n",
    "49. **Verdadero**. Los m茅todos iterativos pueden ser m谩s eficientes en sistemas grandes.  \n",
    "50. **Falso**. La matriz identidad no es diagonalmente dominante, pero cumple otras propiedades.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Respuestas Tema 5: B煤squeda de ra铆ces**\n",
    "\n",
    "51. **Verdadero**. La bisecci贸n siempre converge si \\( f(a)f(b) < 0 \\).  \n",
    "52. **Verdadero**. Newton-Raphson tiene convergencia cuadr谩tica si \\( f'(x) \\neq 0 \\).  \n",
    "53. **Verdadero**. Regula falsi utiliza interpolaci贸n lineal entre dos puntos.  \n",
    "54. **Falso**. Newton-Raphson es m谩s r谩pido si se cumplen las condiciones.  \n",
    "55. **Verdadero**. Si \\( f'(x) = 0 \\), Newton-Raphson falla.  \n",
    "56. **Verdadero**. La secante no necesita la derivada de la funci贸n.  \n",
    "57. **Verdadero**. La convergencia de la secante es superlineal.  \n",
    "58. **Verdadero**. Regula falsi converge incluso en funciones no lineales.  \n",
    "59. **Verdadero**. Bisecci贸n divide el intervalo en dos partes iguales.  \n",
    "60. **Verdadero**. Newton-Raphson puede divergir si el punto inicial es lejano.  \n",
    "61. **Verdadero**. La secante necesita dos valores iniciales.  \n",
    "62. **Verdadero**. Newton-Raphson requiere que la funci贸n sea diferenciable.  \n",
    "63. **Verdadero**. Regula falsi actualiza el extremo donde cambia el signo.  \n",
    "64. **Verdadero**. La bisecci贸n tiene convergencia lineal.  \n",
    "65. **Verdadero**. Newton-Raphson es eficiente por su convergencia cuadr谩tica.  \n",
    "66. **Verdadero**. La secante es una variante de Newton-Raphson.  \n",
    "67. **Verdadero**. Regula falsi converge m谩s r谩pido que bisecci贸n para funciones lineales.  \n",
    "68. **Verdadero**. Newton-Raphson puede \"saltarse\" ra铆ces si hay m煤ltiples ra铆ces.  \n",
    "69. **Verdadero**. La bisecci贸n requiere que \\( f(x) \\) sea continua en el intervalo.  \n",
    "70. **Verdadero**. Newton-Raphson solo necesita un punto inicial, no un intervalo.\n",
    "\n",
    "---\n",
    "\n",
    "Si necesitas que contin煤e hasta las **100 preguntas** o quieres m谩s detalles en alg煤n punto espec铆fico, av铆same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
