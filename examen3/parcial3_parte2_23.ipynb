{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tercer parcial - Algorítmica numérica"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segunda Parte: **Preguntas de desarrollo** - con apuntes, 60min, total 5.3 puntos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 (3.8 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el contexto de la ciencia de datos, la búsqueda de óptimos es un problema mucho más relevante que el de búsqueda de raíces, ya que solemos estar interesados en buscar cuándo una magnitud es máxima o mínima, más que en buscar cuándo una magnitud vale 0. Muchos de los algoritmos de optimización están muy relacionados con los de búsqueda de raíces. Por ejemplo, el método de Newton-Raphson puede adaptarse trivialmente para buscar óptimos.\n",
    "\n",
    "Dada una función $f(x)$, se desea determinar los valores de $x$ para los que $f'(x) = 0$. Las soluciones se conocen como *óptimos* de $f(x)$. Aplicando el método de Newton-Raphson a $f'(x)$, se llega al siguiente esquema iterativo:\n",
    " \n",
    "$$\n",
    "x_{n+1}=x_n-\\frac{f'\\left(x_n\\right)}{f^{\\prime \\prime}\\left(x_n\\right)}\n",
    "$$\n",
    "donde $x_n$ es el candidato actual a solución, $x_{n+1}$ es el nuevo candidato, $f'\\left(x_n\\right)$ es la primera derivada de $f$ evaluada en $x_n$ y $f''\\left(x_n\\right)$ es la segunda derivada de $f$ evaluada en $x_n$.\n",
    "\n",
    "En este ejercicio se pretende resolver progresivamente el siguiente problema: *Dado un conjunto de puntos discretos $(x_i, y_i)$ que definen implícitamente una función $f(x)=y$, obtener un procedimiento que encuentre un óptimo de dicha función.* En particular, se va a trabajar con la función definida implícitamente por los siguientes datos:\n",
    "\n",
    "<center>\n",
    "\n",
    "|    x   |    y   |\n",
    "|--------|--------|\n",
    "| -0.36  |  8.17  |\n",
    "| -0.30  |  6.49  |\n",
    "| -0.24  |  4.73  |\n",
    "| -0.18  |  2.60  |\n",
    "| -0.12  |  1.37  |\n",
    "| -0.06  |  0.77  |\n",
    "|  0.00  |  0.36  |\n",
    "|  0.06  |  0.30  |\n",
    "|  0.12  |  1.19  |\n",
    "|  0.18  |  3.58  |\n",
    "|  0.24  |  6.30  |\n",
    "|  0.30  | 10.88  |\n",
    "|  0.36  | 17.32  |\n",
    "|  0.42  | 23.05  |\n",
    "|  0.48  | 32.55  |\n",
    "|  0.54  | 42.59  |\n",
    "|  0.60  | 55.97  |\n",
    "|  0.66  | 69.38  |\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecuta esta celda, necesitarás estos datos más adelante\n",
    "\n",
    "x = [-0.36, -0.30, -0.24, -0.18, -0.12, -0.06, 0.0, 0.06, 0.12, 0.18, 0.24, 0.30, 0.36, 0.42, 0.48, 0.54, 0.60, 0.66]\n",
    "\n",
    "y = [8.17, 6.49, 4.73, 2.6, 1.37, 0.77, 0.36, 0.3, 1.19, 3.58, 6.3, 10.88, 17.32, 23.05, 32.55, 42.59, 55.97, 69.38] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **(1a) [1 punto] -** Programa una función ```extend_database(x, y)``` que, dada una base de datos en dos listas de abscisas y ordenadas, ```x``` e ```y```, calcule dos nuevas listas ```y_prime``` and ```y_prime_prime``` con los valores de las funciones derivadas primera (```y_prime```) y segunda (```y_prime_prime```) en los nodos. Utiliza diferencias finitas centradas de orden dos para aproximar ambas derivadas. En los extremos, no hace falta que adaptes la expresión: puedes devolver un ```None```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06\n",
      "0.06000000000000005\n",
      "0.05999999999999994\n",
      "0.06000000000000005\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x)-1):\n",
    "    h = x[i+1] - x[i]\n",
    "    print(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asumimios que el paso h es constante y utilizamos diferencias finitas para mallas equispaciadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def df1_centradas_segundo_orden(x: list[float] | tuple[float, ...],\n",
    "                               y: list[float] | tuple[float, ...],\n",
    "                               x_val : float):\n",
    "    \n",
    "    '''derivada primera para diferencias finitas\n",
    "    centradas'''\n",
    "    \n",
    "    \"\"\"\"solo funciona con mallas equispaciadas\"\"\"\n",
    "\n",
    "    index_x_value = np.abs(np.array(x) - x_val).argmin() #paso 1\n",
    "    h = x[1] - x[0] #paso 2\n",
    "\n",
    "    # valor de la izq - valor de la derecha dividido por el 2h\n",
    "    return(y[index_x_value + 1] - y[index_x_value - 1]) / (2 * h) \n",
    "\n",
    "def df2_centradas_segundo_orden(x: list[float] | tuple[float, ...],\n",
    "                                y: list[float] | tuple[float, ...],\n",
    "                                x_val: float):\n",
    "    '''Derivada segunda para diferencias finitas\n",
    "    centradas de segundo orden'''\n",
    "    index_x_value = np.abs(np.array(x) - x_val).argmin()  # Paso 1\n",
    "    h = x[1] - x[0]  # Paso 2\n",
    "\n",
    "    return (y[index_x_value + 1] - 2 * y[index_x_value] + y[index_x_value - 1]) / h**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-28.666666666666664, -32.41666666666667, -28.000000000000004, -15.250000000000002, -8.41666666666667, -3.916666666666667, 6.916666666666667, 27.333333333333336, 42.58333333333333, 60.83333333333334, 91.83333333333333, 101.41666666666667, 126.91666666666664, 162.83333333333337, 195.16666666666669, 223.24999999999994]\n",
      "[-22.222222222222243, -102.77777777777806, 250.0000000000001, 174.99999999999997, 52.777777777777764, 97.22222222222223, 263.88888888888886, 416.66666666666674, 91.66666666666657, 516.666666666667, 516.6666666666663, -197.22222222222197, 1047.222222222221, 150.00000000000273, 927.7777777777748, 8.33333333333365]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18, 16, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_der = [df1_centradas_segundo_orden(x, y, xi) for xi in x[1:-1]]\n",
    "print(y_der)\n",
    "y_2_der = [df2_centradas_segundo_orden(x, y, xi) for xi in x[1:-1]]\n",
    "print(y_2_der)\n",
    "len(x), len(y_der), len(y_2_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOL EJ 1a -> continúa la implementación dada\n",
    "\n",
    "def extend_database(x, y, df1= df1_centradas_segundo_orden, df2= df2_centradas_segundo_orden):\n",
    "    \"\"\"\n",
    "    Extend a database of coordinates with the first and second derivative at each point using\n",
    "    second-order centered finite differences. Return None for the derivatives at the endpoints.\n",
    "\n",
    "    Args:\n",
    "    x (list of float): Abscissas.\n",
    "    y (list of float): Ordinates.\n",
    "\n",
    "    Returns:\n",
    "    y_prime (list of float): First derivatives.\n",
    "    y_prime_prime (list of float): Second derivatives.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializar listas para la primera y segunda derivadas\n",
    "    y_prime = [None] * len(y)  # The first derivative\n",
    "    y_prime_prime = [None] * len(y)  # The second derivative\n",
    "\n",
    "    y_prime[1:-1] = [df1(x, y, xi) for xi in x[1:-1]]\n",
    "    y_prime_prime[1:-1] = [df2(x, y, xi) for xi in x[1:-1]]\n",
    "\n",
    "    return y_prime, y_prime_prime\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([None, -28.666666666666664, -32.41666666666667, -28.000000000000004, -15.250000000000002, -8.41666666666667, -3.916666666666667, 6.916666666666667, 27.333333333333336, 42.58333333333333, 60.83333333333334, 91.83333333333333, 101.41666666666667, 126.91666666666664, 162.83333333333337, 195.16666666666669, 223.24999999999994, None], [None, -22.222222222222243, -102.77777777777806, 250.0000000000001, 174.99999999999997, 52.777777777777764, 97.22222222222223, 263.88888888888886, 416.66666666666674, 91.66666666666657, 516.666666666667, 516.6666666666663, -197.22222222222197, 1047.222222222221, 150.00000000000273, 927.7777777777748, 8.33333333333365, None])\n"
     ]
    }
   ],
   "source": [
    "x = [-0.36, -0.30, -0.24, -0.18, -0.12, -0.06, 0.0, 0.06, 0.12, 0.18, 0.24, 0.30, 0.36, 0.42, 0.48, 0.54, 0.60, 0.66]\n",
    "\n",
    "y = [8.17, 6.49, 4.73, 2.6, 1.37, 0.77, 0.36, 0.3, 1.19, 3.58, 6.3, 10.88, 17.32, 23.05, 32.55, 42.59, 55.97, 69.38] \n",
    "print(extend_database(x, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    " - **(1b) [1 punto] -** Ya que el esquema iterativo anterior puede devolver candidatos $x_{n+1}$ que no estén en el *dataset* original, se necesitará usar un método de interpolación. Programa una función ```step_interpolation(x, y, x_val, k)``` que implemente el algoritmo de **interpolación escalonada** descrito a continuación. Dado un conjunto de datos definidos por una lista de abscisas $x$ y una de ordenadas $y$, se desea obtener una interpolación en el punto $x_{\\mathrm{val}}$. Dicho punto se encontrará acotado por dos valores del dataset original, $x_i$ y $x_{i+1}$ (es decir, $x_i \\leq x_{\\mathrm{val}} < x_{i+1}$). Sea $ \\Delta x = \\frac{x_{i+1} - x_i}{k} $ el *tamaño del paso*, donde $k$ es una constante fijada por el usuario. Definimos $k$ subintervalos iguales entre $x_i$ y $x_{i+1}$, es decir $[x_i + j\\Delta x, x_i + (j+1)\\Delta x)$ para $ j = 0, 1, \\ldots, k-1 $. Entonces, la función de interpolación $y(x)$ en el intervalo $[x_i, x_{i+1}]$ se da por:\n",
    "\n",
    "$$\n",
    "y(x) = \\begin{cases} \n",
    "y_i + \\frac{1}{k} \\cdot \\left( y_{i+1} - y_i \\right) & \\text{si } x_i \\leq x < x_i + \\Delta x \\\\\n",
    "y_i + \\frac{2}{k} \\cdot \\left( y_{i+1} - y_i \\right) & \\text{si } x_i + \\Delta x \\leq x < x_i + 2\\Delta x \\\\\n",
    "\\vdots \\\\\n",
    "y_i + \\frac{k}{k} \\cdot \\left( y_{i+1} - y_i \\right) & \\text{si } x_i + (k-1)\\Delta x \\leq x < x_{i+1}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "o dicho de otra forma, en el subintervalo $j$ la función se interpola por el valor $y_i + \\frac{j}{k} \\cdot \\left( y_{i+1} - y_i \\right)$.\n",
    "\n",
    "La siguiente imagen muestra un croquis de este método:\n",
    "\n",
    "<center>\n",
    "\n",
    "<div>\n",
    "<img src=\"https://drive.upm.es/index.php/apps/files_sharing/ajax/publicpreview.php?x=1680&y=539&a=true&file=2023_parcial3-parte2-ej1_b.png&t=ufEartntJCSlPhf&scalingup=0\" width=\"380\"/>\n",
    "</div>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "Para programar este método, puedes utilizar la siguiente plantilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOL EJ 1b -> COMPLETA LOS HUECOS CON ######\n",
    "\n",
    "def step_interpolation(x, y, x_val, k):\n",
    "    \"\"\"\n",
    "    Implement step interpolation algorithm.\n",
    "    \n",
    "    x (list): List of abscissas.\n",
    "    y (list): Corresponding list of ordinates.\n",
    "    x_val (float): The x value at which to interpolate.\n",
    "    k (int): Number of steps.\n",
    "\n",
    "    returns\n",
    "    y_val (float): Interpolated y value at x_val.\n",
    "    \"\"\"\n",
    "    # Encuentra el intervalo [x_i, x_{i+1}] que contiene a x_val\n",
    "    for i in range(len(x) -1):\n",
    "        if x[i] <= x_val <= x[i+1]:\n",
    "            # Calcula el tamaño de paso\n",
    "            x_left = x[i]\n",
    "            x_right = x[i+1]\n",
    "            delta_x = (x_right - x_left) / k\n",
    "            # Encuentra el subintervalo j que contiene x_val\n",
    "            for j in range(k):\n",
    "                if x_left + j * delta_x < x_val < x_right + (j+1) * delta_x:\n",
    "                    # Calcula la interpolación y devuelve el resultado\n",
    "                    y_val = y[i] + (j/k) * (y[i+1] - y[i])\n",
    "                    return y_val\n",
    "                    \n",
    "    # Se devuelve None si no se ha encontrado el intervalo\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.58333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_interpolation(x, extend_database(x, y)[0], 0.20, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "*\\[Si no has resuelto el apartado (1b), puedes resolver el siguiente apartado usando cualquier método de interpolación de los vistos en el curso\\]*\n",
    "\n",
    " - **(1c) [1 punto] -** Programa una función ```optimize_newton(x, y, x0, tol, max_iter)``` que adapte el método de Newton-Rapshon de búsqueda de raíces para búsqueda de óptimos, según lo explicado al inicio del ejercicio. Utiliza las funciones programadas en los apartados *(1a)* y *(1b)*. ```x``` e ```y``` son las listas que definen el dataset original, ```x0``` es el valor inicial del algoritmo, ```tol``` es la tolerancia objetivo y ```max_iter``` es el máximo número de iteraciones permitidas. Comprueba que al usar el algoritmo sobre el dataset $x / y$ definido arriba, con un valor inicial ```x0 = 0.20``` y una tolerancia de ```tol = 0.003```, se obtiene un óptimo en las proximidades de $x = 0.023$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, -28.666666666666664, -32.41666666666667, -28.000000000000004, -15.250000000000002, -8.41666666666667, -3.916666666666667, 6.916666666666667, 27.333333333333336, 42.58333333333333, 60.83333333333334, 91.83333333333333, 101.41666666666667, 126.91666666666664, 162.83333333333337, 195.16666666666669, 223.24999999999994, None]\n",
      "[None, -22.222222222222243, -102.77777777777806, 250.0000000000001, 174.99999999999997, 52.777777777777764, 97.22222222222223, 263.88888888888886, 416.66666666666674, 91.66666666666657, 516.666666666667, 516.6666666666663, -197.22222222222197, 1047.222222222221, 150.00000000000273, 927.7777777777748, 8.33333333333365, None]\n",
      "dx =  42.58333333333333\n",
      "ddx =  91.66666666666657\n",
      "x_old = 0.2\n",
      "x0 = -0.26454545454545497\n",
      "dx =  -28.666666666666664\n",
      "ddx =  -22.222222222222243\n",
      "x_old = -0.26454545454545497\n",
      "x0 = -1.5545454545454538\n",
      "dx =  None\n",
      "ddx =  None\n",
      "x_old = -1.5545454545454538\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 43\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m x0\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x0, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno se ha encontrado el x esperado en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iteraciones. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tiene un error de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mabs\u001b[39m(x0\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mx_old)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moptimize_newton\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.003\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Debe ser aproximadamente 0.023\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[37], line 34\u001b[0m, in \u001b[0;36moptimize_newton\u001b[1;34m(x, y, x0, tol, max_iter)\u001b[0m\n\u001b[0;32m     32\u001b[0m x_old \u001b[38;5;241m=\u001b[39m x0\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_old = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_old\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m x0 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mdx\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mddx\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx0 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(x0 \u001b[38;5;241m-\u001b[39m x_old) \u001b[38;5;241m<\u001b[39m tol:\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# SOL EJ 1c \n",
    "def optimize_newton(x, y, x0, tol=3e-3, max_iter=100):\n",
    "    \"\"\"\n",
    "    Adapt the Newton-Raphson root-finding method to find a local optimum of a given dataset.\n",
    "    Utilizes the previously programmed `extend_database` function to get the derivatives.\n",
    "\n",
    "    Args:\n",
    "    x (list of float): Abscissas.\n",
    "    y (list of float): Ordinates.\n",
    "    x0 (float): Initial guess for the location of the optimum.\n",
    "    tol (float): Tolerance for stopping criterion.\n",
    "    max_iter (int): Maximum number of iterations to perform.\n",
    "\n",
    "    Returns:\n",
    "    float: The x-value of the local optimum.\n",
    "    \"\"\"\n",
    "\n",
    "    y_prime, y_double_prime = extend_database(x, y)\n",
    "    print(y_prime)\n",
    "    print(y_double_prime)\n",
    "\n",
    "    for i in range(1, max_iter):\n",
    "\n",
    "        dx = step_interpolation(x, y_prime, x0, 8)\n",
    "        print('dx = ',dx)\n",
    "        ddx = step_interpolation(x, y_double_prime, x0, 8)\n",
    "        print('ddx = ', ddx)\n",
    "        \n",
    "        # if dx is None or ddx is None:\n",
    "        #     raise ValueError(\"La interpolación devolvió None. Verifica el intervalo.\")\n",
    "\n",
    "        x_old = x0\n",
    "        print(f'x_old = {x_old}')\n",
    "        x0 -= dx/ddx\n",
    "        print(f'x0 = {x0}')\n",
    "\n",
    "        if abs(x0 - x_old) < tol:\n",
    "            return x0\n",
    "        \n",
    "\n",
    "    return x0, f'no se ha encontrado el x esperado en {max_iter} iteraciones. {x} tiene un error de {abs(x0 - x_old)} '\n",
    "\n",
    "print(optimize_newton(x, y, x0=0.20, tol=0.003, max_iter=100))  # Debe ser aproximadamente 0.023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "*\\[el siguiente apartado puede abordarse sin problema sin haber resuelto ninguno de los apartados anteriores.\\]*\n",
    "\n",
    " - **(1d) [0.8 puntos] -** Analiza críticamente el método anterior. ¿Crees que es un método estable? ¿Qué inconvenientes le ves en una situación genérica (es decir, en el caso en el que $x$ e $y$ sean datos recogidos en un escenario incierto)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOL 1d\n",
    "\n",
    "# puede pasar que x se vaya a los extremos donde no tenemos definidas las derivadas\n",
    "# lo que supone un gran porblema pq no podemos evaluar en Nones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "## Ejercicio 2 (1.5 puntos)\n",
    "\n",
    "Como sabes, el método del **Gradiente Conjugado** es un algoritmo eficiente para la búsqueda de soluciones de sistemas lineales, especialmente adecuado para matrices dispersas. A continuación se da una posible implementación de este método: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8, 20])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2,3], [4, 5, 6]])\n",
    "b = np.array([1,2,1])\n",
    "\n",
    "a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_conj_grad(A, b, x0, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Implements the conjugate gradient algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    A   : coefficient matrix of the system\n",
    "    b   : vector of independent terms\n",
    "    x0  : initial vector\n",
    "    tol : tolerance for the convergence of the algorithm\n",
    "\n",
    "    Returns:\n",
    "    x   : solution vector\n",
    "    k + 1 : number of iterations performed\n",
    "    \"\"\"\n",
    "    \n",
    "    def av_standard(v): #va a devolver un vector\n",
    "        \"\"\" \n",
    "        Performs the product of the coefficient matrix A by a given vector 'v'.\n",
    "        Uses the standard 'dot' product function from NumPy.\n",
    "        \"\"\"\n",
    "        return A.dot(v)\n",
    "\n",
    "    # Inicialización de variables\n",
    "    x = x0  # Vector inicial\n",
    "    r = b - av_standard(x)  # Residuo inicial\n",
    "    s = r.copy()  # Dirección de búsqueda inicial (s_0 = r_0)\n",
    "\n",
    "    # Bucle principal del algoritmo del gradiente conjugado\n",
    "    for k in range(len(b)):\n",
    "        # Producto de A y la dirección de búsqueda actual\n",
    "        As = av_standard(s)\n",
    "\n",
    "        # Cálculo de la longitud del paso alpha_k\n",
    "        alpha = np.dot(s, r) / np.dot(s, As)\n",
    "\n",
    "        # Actualización de la solución x\n",
    "        x += alpha * s\n",
    "\n",
    "        # Cálculo del nuevo residuo\n",
    "        r_new = b - av_standard(x)\n",
    "\n",
    "        # Verificación de la condición de parada (norma del residuo)\n",
    "        if np.linalg.norm(r_new) <= tol:\n",
    "            break\n",
    "\n",
    "        # Cálculo del factor beta_k para la actualización de la dirección de búsqueda\n",
    "        beta = -np.dot(r_new, As) / np.dot(s, As)\n",
    "\n",
    "        # Actualización de la dirección de búsqueda s\n",
    "        s = r_new + beta * s\n",
    "\n",
    "        # Actualización del residuo\n",
    "        r = r_new\n",
    "\n",
    "    return x, k + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el método anterior implementa una función dentro del propio método que calcula simplemente el producto de la matriz de coeficientes $A$ por un vector $v$ dado. Dicha función usa el producto general de ```numpy``` (método ```dot```)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio se propone adaptar el método del Gradiente Conjugado para el caso en que la matriz de coeficientes $A$ sea una matriz *skyline*. Las matrices *skyline* son un tipo especial de matrices simétricas y dispersas con una estructura espacial muy particular: para la parte triangular superior, en cada columna los elementos de la matriz son todos nulos hasta un cierto índice, a partir del cual ningún elemento es nulo hasta llegar a la diagonal.\n",
    "\n",
    "La forma típica de almacenar estas matrices es usando dos arrays unidimensionales. El primero contiene los elementos no nulos de cada columna, puestos uno a continuación del siguiente. Se utiliza otro array puntero que indica en qué índice del array original hay un cambio de columna. Observa la siguiente imagen que muestra un ejemplo de matriz skyline y su almacenamiento en esta estructura de dos arrays:\n",
    "\n",
    "<center>\n",
    "\n",
    "<div>\n",
    "<img src=\"https://drive.upm.es/index.php/apps/files_sharing/ajax/publicpreview.php?x=1680&y=539&a=true&file=2023_parcial3-parte2-ej2.png&t=LdlR8aeWwVovtB5&scalingup=0\" width=\"680\"/>\n",
    "</div>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La figura muestra un ejemplo de estructura skyline pero, en general, otra matriz skyline tendrá en cada columna un número de elementos no nulos distinto al de este ejemplo.\n",
    "\n",
    "La siguiente matriz es un ejemplo concreto de matriz skyline:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "2 & 8 & 0 & 4 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "8 & 7 & 9 & 9 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 9 & 4 & 9 & 7 & 0 & 1 & 0 & 0 \\\\\n",
    "4 & 9 & 9 & 1 & 3 & 0 & 3 & 0 & 0 \\\\\n",
    "0 & 0 & 7 & 3 & 6 & 4 & 6 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 4 & 6 & 8 & 5 & 1 \\\\\n",
    "0 & 0 & 1 & 3 & 6 & 8 & 1 & 1 & 4 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 5 & 1 & 4 & 6 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 1 & 4 & 6 & 10 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "cuya representación skyline con los dos arrays descritos anteriormente es:\n",
    "$$\n",
    "a_{data} = \\left[ 2, 8, 7, 9, 4, 4, 9, 9, 1, 7, 3, 6, 4, 6, 1, 3, 6, 8, 1, 5, 1, 4, 1, 1, 4, 6, 10 \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_{pointer} = \\left[0, 1,    3,    5,          9,       12,   14,            19,      22 \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **(2a) [1.5 puntos] -** Adaptar el método del Gradiente Conjugado para trabajar con matrices skyline. Programa una función ```skyline_conj_grad(matrix_data, matrix_pointer, b, x0, tol=1e-10)``` que implemente un método del gradiente conjugado adaptado a matrices skyline. Observa que ahora la información de la matriz de coeficientes es pasada en dos arrays ```matrix_data, matrix_pointer``` (los descritas anteriormente). Puedes utilizar la plantilla dada a continuación. Si lo haces, observa que el único cambio esencial respecto al método del gradiente conjugado dado anteriormente es la función interna que calcula el producto matriz-vector. Tendrás que adaptarla para el caso de matrices skyline, aprovechando la estructura espacial de estas matrices para optimizar la implementación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOL 2a -> COMPLETA LOS HUECOS CON ######.\n",
    "# El único cambio notable es la función que calcula el producto matriz-vector. El resto es igual que en el caso estándar.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def skyline_conj_grad(matrix_data, matrix_pointer, b, x0, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Implements the conjugate gradient algorithm.\n",
    "\n",
    "    Parameters:\n",
    "    matrix_data    : array containing the non-zero elements of the skyline matrix, column by column\n",
    "    matrix_pointer : array containing the indices of the first non-zero element in each column of the skyline matrix\n",
    "    b              : vector of independent terms\n",
    "    x0             : initial vector\n",
    "    tol            : tolerance for the convergence of the algorithm\n",
    "\n",
    "    Returns:\n",
    "    x      : solution vector\n",
    "    k + 1  : number of iterations performed\n",
    "    \"\"\"\n",
    "    \n",
    "    def av_skyline(v):\n",
    "        \"\"\"\n",
    "        Calculates the product of a symmetric skyline matrix by a vector.\n",
    "\n",
    "        Parameters:\n",
    "        v   : vector with which the matrix is multiplied\n",
    "\n",
    "        Returns:\n",
    "        av  : the result of the multiplication\n",
    "        \"\"\"\n",
    "        n = len(v)\n",
    "        av = np.zeros(n)  # Inicializar el vector resultante\n",
    "\n",
    "        for i in range(n):\n",
    "            # Determinar el inicio y el fin de los elementos no nulos en la columna i\n",
    "            start = matrix_pointer[i]\n",
    "            end = matrix_pointer[i+1]\n",
    "\n",
    "            # Iterar sobre los elementos no nulos de la columna i\n",
    "            for index in range(start, end):\n",
    "                j = i - (end - index - 1)  # Calcular el índice de la fila correspondiente\n",
    "\n",
    "                # Añadir la contribución de A[i, j] * v[j] al elemento i del vector resultante\n",
    "                av[i] += matrix_data[index] * v[j]\n",
    "\n",
    "                if i != j:\n",
    "                    # Añadir la contribución simétrica para A[j, i] * v[i]\n",
    "                    # Esto es necesario debido a la simetría de la matriz\n",
    "                    av[j] += matrix_data[index] * v[i]\n",
    "\n",
    "        return av\n",
    "\n",
    "    # A PARTIR DE AQUÍ EL CÓDIGO ES IGUAL AL DEL CASO ESTÁNDAR - NO DEBERÍAS TENER QUE CAMBIAR/AÑADIR NADA\n",
    "\n",
    "    # Inicialización de variables\n",
    "    x = x0  # Vector inicial\n",
    "    r = b - av_skyline(x)  # Residuo inicial\n",
    "    s = r.copy()  # Dirección de búsqueda inicial (s_0 = r_0)\n",
    "\n",
    "    # Bucle principal del algoritmo del gradiente conjugado\n",
    "    for k in range(len(b)):\n",
    "        # Producto de A y la dirección de búsqueda actual\n",
    "        As = av_skyline(s)\n",
    "\n",
    "        # Cálculo de la longitud del paso alpha_k\n",
    "        alpha = np.dot(s, r) / np.dot(s, As)\n",
    "\n",
    "        # Actualización de la solución x\n",
    "        x += alpha * s\n",
    "\n",
    "        # Cálculo del nuevo residuo\n",
    "        r_new = b - av_skyline(x)\n",
    "\n",
    "        # Verificación de la condición de parada (norma del residuo)\n",
    "        if np.linalg.norm(r_new) <= tol:\n",
    "            break\n",
    "\n",
    "        # Cálculo del factor beta_k para la actualización de la dirección de búsqueda\n",
    "        beta = -np.dot(r_new, As) / np.dot(s, As)\n",
    "\n",
    "        # Actualización de la dirección de búsqueda s\n",
    "        s = r_new + beta * s\n",
    "\n",
    "        # Actualización del residuo\n",
    "        r = r_new\n",
    "\n",
    "    return x, k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solución mediante 'np.linalg.solve': [-1.6822285   0.18148133  1.26489938  0.97815159 -1.45678985  0.33722626\n",
      "  0.70123519  0.55964956  0.39567255]\n",
      "Solución mediante gradiente conjugado estándar: [-1.6822285   0.18148133  1.26489938  0.97815159 -1.45678985  0.33722626\n",
      "  0.70123519  0.55964956  0.39567255]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 9 is out of bounds for axis 0 with size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolución mediante \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnp.linalg.solve\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(A,\u001b[38;5;250m \u001b[39mb)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolución mediante gradiente conjugado estándar: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstandard_conj_grad(A,\u001b[38;5;250m \u001b[39mb,\u001b[38;5;250m \u001b[39mx0\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros_like(b),\u001b[38;5;250m \u001b[39mtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-10\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolución mediante gradiente conjugado adaptado para matrices skyline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mskyline_conj_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43ma_pointer\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mx0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-10\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[50], line 58\u001b[0m, in \u001b[0;36mskyline_conj_grad\u001b[1;34m(matrix_data, matrix_pointer, b, x0, tol)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# A PARTIR DE AQUÍ EL CÓDIGO ES IGUAL AL DEL CASO ESTÁNDAR - NO DEBERÍAS TENER QUE CAMBIAR/AÑADIR NADA\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Inicialización de variables\u001b[39;00m\n\u001b[0;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m x0  \u001b[38;5;66;03m# Vector inicial\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m r \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m-\u001b[39m \u001b[43mav_skyline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Residuo inicial\u001b[39;00m\n\u001b[0;32m     59\u001b[0m s \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Dirección de búsqueda inicial (s_0 = r_0)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Bucle principal del algoritmo del gradiente conjugado\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 38\u001b[0m, in \u001b[0;36mskyline_conj_grad.<locals>.av_skyline\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Determinar el inicio y el fin de los elementos no nulos en la columna i\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     start \u001b[38;5;241m=\u001b[39m matrix_pointer[i]\n\u001b[1;32m---> 38\u001b[0m     end \u001b[38;5;241m=\u001b[39m \u001b[43mmatrix_pointer\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Iterar sobre los elementos no nulos de la columna i\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, end):\n",
      "\u001b[1;31mIndexError\u001b[0m: index 9 is out of bounds for axis 0 with size 9"
     ]
    }
   ],
   "source": [
    "# Comprueba tus resultados resolviendo el siguiente sistema:\n",
    "\n",
    "A = np.array([[ 2,  8,  0,  4,  0,  0,  0,  0,  0],\n",
    "              [ 8,  7,  9,  9,  0,  0,  0,  0,  0],\n",
    "              [ 0,  9,  4,  9,  7,  0,  1,  0,  0],\n",
    "              [ 4,  9,  9,  1,  3,  0,  3,  0,  0],\n",
    "              [ 0,  0,  7,  3,  6,  4,  6,  0,  1],\n",
    "              [ 0,  0,  0,  0,  4,  6,  8,  5,  1],\n",
    "              [ 0,  0,  1,  3,  6,  8,  1,  1,  4],\n",
    "              [ 0,  0,  0,  0,  0,  5,  1,  4,  6],\n",
    "              [ 0,  0,  0,  0,  1,  1,  4,  6, 10]], dtype=float)\n",
    "\n",
    "b = np.array([  2,  8,  6,  5,  9,  5,  1,  7,  9], dtype=float)\n",
    "\n",
    "# Matriz A dada en formato skyline\n",
    "a_data    = np.array([2, 8, 7, 9, 4, 4, 9, 9, 1, 7, 3, 6, 4, 6, 1, 3, 6, 8, 1, 5, 1, 4, 1, 1, 4, 6, 10], dtype=float)\n",
    "a_pointer = np.array([0, 1, 3, 5, 9, 12, 14, 19, 22], dtype=int)\n",
    "\n",
    "print(f\"Solución mediante 'np.linalg.solve': {np.linalg.solve(A, b)}\")  \n",
    "\n",
    "print(f\"Solución mediante gradiente conjugado estándar: {standard_conj_grad(A, b, x0=np.zeros_like(b), tol=1e-10)[0]}\")\n",
    "\n",
    "print(f\"Solución mediante gradiente conjugado adaptado para matrices skyline: {skyline_conj_grad(a_data, a_pointer, b, x0=np.zeros_like(b), tol=1e-10)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
